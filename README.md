# Spark with Parameter Server.
Benchmarking Parameter Server libraries for Spark. 

Benchmark code is simple: incrementally update a single parameter in a distributed fashion. Benchmarks are aimed to simulate the workflow of incremetal-update algorithms (i.e. Gradient Descent).

The following libraries are benchmarked:

* Conventional spark (the way incremental update is usually done in spark)
* PS on Spark - https://github.com/chouqin/spark/tree/ps-on-master
* DistML - https://github.com/intel-machine-learning/DistML

For more information about parameeter server implementations visit projects' websites.

## Running Benchmarks

Before running cluster benchmarks ensure you have started Spark Cluster, this should do the job:

	$  /usr/local/spark-ps/sbin/start-all.sh

Scripts for running the benchmarks on local node or on a cluster are provided:

	$ ./benchmark-local.sh 4 100 1000000 PSUpdateBenchmark output.txt

	$ ./benchmark-cluster.sh 4 100 1000000 DistMLUpdateBenchmark output.txt

Scripts need to be configured in order to run properly (i.e. set up cluster node names, set up jar file paths). Please refer to script files for detailed information about running benchmarks

## Computing Statistics

For aggregating stats generated by benchmark, the stats.sh script can be used as follows:

	$ ./stats.sh local output.txt

	$ ./stats.sh cluster output.txt

Please refer to stats script for detailed information about available metrics.

## Experiment results

We setup and experiment on a 6-node cluster. Each node in cluster has an Intel Xeon CPU E31240 @ 3.30GHz processor with a Gigabit network controller. Tests perform parameter get and parameter set of a 1-million-doubles vector. We run for 100 iterations and present the average iteration time.

<table>
    <tr>
        <th>Partitions</th>
        <th>Spark</th>
        <th>PS on Spark</th>
        <th>DistML</th>
    </tr>
    <tr>
        <td>2</td>
        <td>0.658223</td>
        <td>0.543579</td>
        <td>0.936802</td>
    </tr>
    <tr>
        <td>3</td>
        <td>0.764838</td>
        <td>0.686946</td>
        <td>1.031660</td>
    </tr>
    <tr>
        <td>4</td>
        <td>0.851536</td>
        <td>0.780065</td>
        <td>1.102909</td>
    </tr>
    <tr>
        <td>5</td>
        <td>0.863518</td>
        <td>0.884226</td>
        <td>1.194329</td>
    </tr>
    <tr>
        <td>8</td>
        <td>0.925723</td>
        <td>1.106068</td>
        <td>1.518073</td>
    </tr>
    <tr>
        <td>16</td>
        <td>1.100667</td>
        <td>1.762331</td>
        <td>2.445314</td>
    </tr>
    <tr>
        <td>32</td>
        <td>1.303568</td>
        <td>3.509727</td>
        <td>3.997999</td>
    </tr>
    <tr>
        <td>64</td>
        <td>1.723489</td>
        <td>7.072663</td>
        <td>7.690554</td>
    </tr>
</table>
